## [Use Case: Museum data with a dash of RDF sideline](/blog/2015-08-11/)
*Posted by Shaun Osborne, 11 Aug 2015*

Originally posted at Museums-IO which we've rolled into [dataRefinery.io](http://www.datarefinery.io). Reposted here updated.

Museum data is rich, interesting, might reflect years of research, and can be a beautiful encapsulation of the details of an object designed to serve people who are specialists about that object.. and.. you could go on and on about its positive characteristics. That opening sentence, when you 'read between the lines', also tells you a couple of things in a nutshell: Museum data is not simple, and it's not standard. There are [historical reasons](/blog/2015-07-23/) for this..

I think that will remain forever true - I doubt any in the sector would (or should) support a 'dumbing down' of the primary data. So, what exactly is the problem we are trying to solve?

You could argue that we've 'cracked' the online catalogue and aggregation goals of old. If that is accepted, then I would argue that moving beyond discovery (through either singular or massively aggregated catalogues) means a few things:

* interfaces which allow serendipity (think 'browse' but on 'steroids', with strong interconnects to a wide range of web published materials, not just our own),
* an ability to use standard tools (reporting, data analysis, data visualisation etc) over our data sets, and
* integration between a variety of systems is key if 1 & 2 are to be true. Integration is also the key to 'open data' provision - this is the bedrock of open data and our ability to supply and consume data 'at will'.

This requires more connections within and between our data sets. The technical jargon for this is 'semantic' and has been embodied in enthusiasm for standards like RDF.

### RDF Sideline..
RDF is mathematically true & beautiful. The tools available to 'query' RDF data are currently fairly sparse. The tools are also fairly terse, requiring precision in the questions you ask: implying you have precision in your data to start with. Whilst the tools are sparse & terse, the standard encoding for RDF is incredibly verbose. RDF was designed to be created & handled by machines, not humans. RDF thrives when it can encode a series of 'truth assertions' up and down, and across, chains of information.

Retro-fitting these types of assertions to existing data is not going to happen: think 'all web pages  will have embedded dublin core metadata' from our past and you can see why I think this.

RDF is a 'utopia too far' at present: there are intermediate data steps to solve before RDF will be able to come into its own. Or more likely, RDF won't be the technology in which rich interconnects between data will be expressed. Internet technology has an uncanny knack of whittling technology down to size: the true, elegant and complicated technologies get supplanted into 'good enough', pragmatic,  and highly usable technologies (most of which rely on the core concepts of the original idea to achieve their end).

A final, simple, observation is that museum data is often unable to 'assert truths', there's an awful lot of 'might be', 'dated around', 'we think this might have been made by' type assertions within museum data: this makes it a poor data candidate to be expressed in a data standard which at its core is about using logical assertion chains to provide data sets which can encode 'truths' for a given knowledge domain.

Returning to semantics, in its more general sense (establishing connections between facts, terms or content), it will absolutely be required as an enabler to 'browsable serendipity' and/or creating meaningful 'standard' data sets which can be used in current and emerging 'user tools'. The 64,000 dollar question is how? That I don't know the exact answer to (surprise, surprise), but I can anticipate what its main characteristic will be: it will have to be machine generated, the open data movement will provide access to data sets which will allow machine processing on a massive scale which will, in turn, means it will become possible to check the 'confidence' of these machine generated connections (semantics) statistically over many data sets, human intervention will be the exception (to correct obvious bloopers by machines) rather than the norm.

"Museums meet big data science" - we have a few basic building block hurdles to overcome before we can truly leverage the benefits that the semantic stage will bring.

Shaun Osborne

August 2015
