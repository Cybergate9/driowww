## [Use case: Museum Data, a historical perspective](/blog/2015-07-23/)
*Posted by Shaun Osborne, 23 July 2015*

Originally posted at Museums-IO which we've rolled into [dataRefinery.io](http://www.datarefinery.io). Reposted here updated.

The thing about collections management systems are they are not new: neither to the museums who have been recording things (albeit in ledgers & card indexes) for an age, nor to the technologists who have been dealing with 'records management' since punch cards.
Collections management has too suffered its fair share of, what I like to call, the "we're special syndrome": a well known phenomena in IT projects where clients create specifications to try and fit technology into their manual practices rather than reviewing their practices and re-designing them to fit well in a combined automated/manual system (enabling the use of prior knowledge, standards and technologies).

This is not to say that there is no valid variations in collections management practices; just that creating 'silver bullets' to retrofit technology to people and organisational quirks is a fast way to reduce IT return on investment to its least efficient (or, more succinctly, a waste of money).

Let's take a quick romp through the 'museum documentation' history we've been through:

* All documentation on paper (ledges, card indexes, pen marking up in standard catalogues, photos glued to pages, etc)
* The transition to simple single user databases (using tech. like DBASE, FIlemaker, Access, Lotus, Excel - sometimes these were replacements for paper systems and sometimes they were supplementary to paper systems)
* The transition to 'whole of organisation' proprietary 'collections management systems'

And it can not be understated that throughout all of this history there has been a total reliance on supplementary paper based records management - aka filing cabinets and archive boxes full of important bits of paper. This is not a problem per se, but forgetting it when you are designing or using digital based systems will mean you are ignoring reality.

Now, let's try and unpack some 'functionality' in each of these 'technologies'.

Paper Records. The key here was 'find ability' and capturing knowledge. An accession ledger allowed you to find acquisition information about an object (probably stored in a filing cabinet somewhere) through a series of cross referenced identifiers. Object based card systems allowed you to record *anything* about an object in a structured or unstructured manner. A filing cabinet containing a folder for an exhibition could contain any and all information on paper about that exhibition. Massive amounts of effort went into designing and organising these systems.

Simple databases. The key here was speed and a hope was discoverability and reporting. Simple single user databases were a cross between ledgers and detailed card systems although couldn't really replace either in their entirety. The effort to re-key all of the data into these systems was heroic. Often these were built by subject specialist experts which had the upside of fielding based directly on the materials being catalogued, and the downside that the data structures were, at best, non standard. This period is also a good lesson in preservation - many of these databases 'disappeared' when their host applications went out of date in the late 90's, or the curator who created them retired..

Whole of organisation systems. These systems were originally one of those IT 'silver bullets'. As time passed 'find ability', search-ability, & reporting were key functions desired. The difficulty in adapting these systems to different specialisations and materials cannot be overstated, and it lead to a very heavy reliance on unstructured data. The Internet added the desire to publish this material online. As we have all seen over the past decade there are no silver bullets - these systems are somewhat complicated and often don't live up to expectations.

The efforts around controlled vocabularies, importing, or re-keying legacy data, and even just deciding what fields to use and how to use them, have been, to repeat myself, heroic.
Add to this digitisation, the creation of images for objects in collections, well before good systems for digital asset management appeared and more complications compounded onto the original.

Latterly the desire for open data, and more specifically linked open data, or semantically connected data, is pressuring the underlying systems once again.

And to be clear, and return to our focus, the pressure isn't a traditionally technical one (e.g. its not the systems are slow or can't be built), it's one of retrofitting desired functionality to systems which in most cases are already too specialised and complicated. User expectations are also playing a larger role today - people experience very sophisticated 'database and web applications' everyday on the Internet.. this raises the bar, they expect all systems to work this speedily and flexibly.

Why this is all so, must be puzzling to those with data management knowledge from outside the cultural sector. Create a data structure, put it on a database management system (DBMS), build an application for users to find and edit records, attach industry standard reporting tools to the DBMS etc.
This is easy isn't it?

Well, it would be if the data was first normal form (1NF) relational data like the IT industry has been dealing with over the past 40 years.
But museum data (to take but one example) is not structured (another way of saying it's not 1NF). It is very unstructured and this usually leads to using a group of technologies loosely called 'post-relational databases' to implement collections management systems.

By unstructured we mean, take for example, a group of four fields which, together as a group, can be repeated any number of times inside a single record, multiply this up and often there are dozens of these multi-field, multi-repeating entities inside a single record - this is a complete anathema to a standard relational database designer.

Post-relational databases are an oddity created to handle unstructured data in a way that would make it 'sort of' structured. These technologies are not 'rocket science' complicated but they are sufficiently far from the technical mainstream that it takes time for a technical person to transfer skills onto this type of technology and become proficient.

Taking all these challenges into account means many organisations are now 'at the mercy' of their post-relational technologies and very unstructured data.

There is a good news story though. Technology like most things has an uncanny knack of cycling. In the current technology cycle unstructured data has become a mainstream problem. The benefit here should be obvious - once mainstream, a 'technical problem', such as a global need to handle unstructured as well as structured data, on massive scales, means that a lot of money and clever people are drawn toward solving that problem. This is great news for 'museum data'. We will have 'technology stacks' that are designed from the 'ground up' to handle our primary data type - unstructured or semi structured data.

We are beginning to see pilots and implementations of applying 'big data tools' to museum data problems. JSON can represents both structured and unstructured data well. NoSQL stores and indexers can provide functional and performance increases close to a full order of magnitude. Streaming and asynchronous technologies can move 'open data' to a whole new level.

We are looking forward to interesting times ahead for cultural data.
